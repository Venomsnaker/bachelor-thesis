{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up SelfCheckGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import modeling_selfcheck\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "selfcheck_1gram = modeling_selfcheck.SelfCheckNgram(n=1)\n",
    "selfcheck_2gram = modeling_selfcheck.SelfCheckNgram(n=2)\n",
    "selfcheck_3gram = modeling_selfcheck.SelfCheckNgram(n=3)\n",
    "selfcheck_4gram = modeling_selfcheck.SelfCheckNgram(n=4)\n",
    "selfcheck_5gram = modeling_selfcheck.SelfCheckNgram(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Wikibio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/dataset_v3.json\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    \n",
    "dataset = json.loads(content)\n",
    "print(\"The length of the dataset: {}\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_mapping = {\n",
    "    'accurate': 0.0,\n",
    "    'minor_inaccurate': 0.5,\n",
    "    'major_inaccurate': 1.0,\n",
    "}\n",
    "\n",
    "human_label_detect_False   = {}\n",
    "human_label_detect_True    = {}\n",
    "human_label_detect_False_h = {}\n",
    "\n",
    "for i_ in range(len(dataset)):\n",
    "    dataset_i = dataset[i_]\n",
    "    idx = dataset_i[\"wiki_bio_test_idx\"]\n",
    "    raw_label = np.array([label_mapping[x] for x in dataset_i['annotation']])\n",
    "    \n",
    "    human_label_detect_False[idx] = (raw_label > 0.499).astype(np.int32).tolist()\n",
    "    human_label_detect_True[idx] = (raw_label < 0.499).astype(np.int32).tolist()\n",
    "    average_score = np.mean(raw_label)\n",
    "    if (average_score < 0.99):\n",
    "        human_label_detect_False_h[idx] = (raw_label > 0.99).astype(np.int32).tolist()\n",
    "        \n",
    "print(\"Length of False:\", len(human_label_detect_False))\n",
    "print(\"Length of True:\", len(human_label_detect_True)) \n",
    "print(\"Length of False_h:\", len(human_label_detect_False_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheck Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores_1gram = {}\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x = dataset[i]\n",
    "    idx = dataset[i]['wiki_bio_test_idx'] \n",
    "\n",
    "    scores_1gram[idx] = selfcheck_1gram.predict(\n",
    "        passage= x['gpt3_text'],\n",
    "        sentences = x['gpt3_sentences'],           \n",
    "        sampled_passages = x['gpt3_text_samples'],\n",
    "    )\n",
    "\n",
    "with open(\"data/scores_ngram/scores_1gram.json\", \"w\") as outfile: \n",
    "    json.dump(scores_1gram, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheck 2-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores_2gram = {}\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x = dataset[i]\n",
    "    idx = dataset[i]['wiki_bio_test_idx'] \n",
    "\n",
    "    scores_2gram[idx] = selfcheck_2gram.predict(\n",
    "        passage= x['gpt3_text'],\n",
    "        sentences = x['gpt3_sentences'],           \n",
    "        sampled_passages = x['gpt3_text_samples'],\n",
    "    )\n",
    "\n",
    "with open(\"data/scores_ngram/scores_2gram.json\", \"w\") as outfile: \n",
    "    json.dump(scores_2gram, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheck 3-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores_3gram = {}\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x = dataset[i]\n",
    "    idx = dataset[i]['wiki_bio_test_idx'] \n",
    "\n",
    "    scores_3gram[idx] = selfcheck_3gram.predict(\n",
    "        passage= x['gpt3_text'],\n",
    "        sentences = x['gpt3_sentences'],           \n",
    "        sampled_passages = x['gpt3_text_samples'],\n",
    "    )\n",
    "\n",
    "with open(\"data/scores_ngram/scores_3gram.json\", \"w\") as outfile: \n",
    "    json.dump(scores_3gram, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheck 4-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores_4gram = {}\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x = dataset[i]\n",
    "    idx = dataset[i]['wiki_bio_test_idx'] \n",
    "\n",
    "    scores_4gram[idx] = selfcheck_4gram.predict(\n",
    "        passage= x['gpt3_text'],\n",
    "        sentences = x['gpt3_sentences'],           \n",
    "        sampled_passages = x['gpt3_text_samples'],\n",
    "    )\n",
    "\n",
    "with open(\"data/scores_ngram/scores_4gram.json\", \"w\") as outfile: \n",
    "    json.dump(scores_4gram, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheck 5-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores_5gram = {}\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x = dataset[i]\n",
    "    idx = dataset[i]['wiki_bio_test_idx'] \n",
    "\n",
    "    scores_5gram[idx] = selfcheck_5gram.predict(\n",
    "        passage= x['gpt3_text'],\n",
    "        sentences = x['gpt3_sentences'],           \n",
    "        sampled_passages = x['gpt3_text_samples'],\n",
    "    )\n",
    "\n",
    "with open(\"data/scores_ngram/scores_5gram.json\", \"w\") as outfile: \n",
    "    json.dump(scores_5gram, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
