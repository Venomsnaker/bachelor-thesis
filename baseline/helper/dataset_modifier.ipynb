{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load HaluEval 2.0\n",
      "Length of Bio-Medical: 200.\n",
      "Length of Education: 200.\n",
      "Length of Finance: 200.\n",
      "Length of Open-Domain: 200.\n",
      "Length of Science: 200.\n",
      "\n",
      "Loading SelfCheckGPT\n",
      "The length of the dataset: 238.\n"
     ]
    }
   ],
   "source": [
    "from utils import read_data\n",
    "\n",
    "OUTPUT_DIR = '../data'\n",
    "folder_path_halueval = '../halu_eval_2/annotation/human_annotation'\n",
    "folder_path_selfcheckgpt = '../self_check_gpt/data/dataset_v3.json'\n",
    "\n",
    "dataset_halu_eval, dataset_self_check_gpt = read_data(folder_path_halueval, folder_path_selfcheckgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Bio-Medical: 200.\n",
      "Length of Education: 200.\n",
      "Length of Finance: 200.\n",
      "Length of Open-Domain: 200.\n",
      "Length of Science: 200.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "FOLDER_PATH_HALUEVAL_PROCESSED = \"../data/halu_eval_2\"\n",
    "\n",
    "def read_processed_data():\n",
    "    dataset_halu_eval_processed = {}\n",
    "    \n",
    "    for file_name in os.listdir(FOLDER_PATH_HALUEVAL_PROCESSED):\n",
    "        file_path = os.path.join(FOLDER_PATH_HALUEVAL_PROCESSED, file_name)\n",
    "        file_name = file_name.replace(\".json\", \"\")\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        dataset_halu_eval_processed[file_name] = json.loads(content)\n",
    "        print(f\"Length of {file_name}: {len(dataset_halu_eval_processed[file_name])}.\")\n",
    "    return dataset_halu_eval_processed\n",
    "    \n",
    "dataset_halu_eval_processed = read_processed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate OpenAI client... model = solar-pro\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "\n",
    "from solar_pro import SolarPro\n",
    "SAMPLE_PASSAGES_SIZE = 5\n",
    "SAMPLE_PASSAGES_RESPOND_TEMP = 0.7 # [0, 2], Default=0.7\n",
    "SENTENCE_ENDINGS = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!|\\n)\\s*'\n",
    "LLM = SolarPro(\n",
    "    client_type=\"openai\", \n",
    "    base_url=\"https://api.upstage.ai/v1/solar\", \n",
    "    model=\"solar-pro\", \n",
    "    api_key=os.getenv('UPSTAGE_API_KEY')\n",
    ")\n",
    "\n",
    "def get_sample_passages(\n",
    "    prompt: str,\n",
    "    respond_length: int,\n",
    "    respond_word_counter: int,\n",
    "    sample_passages_size = SAMPLE_PASSAGES_SIZE,\n",
    "    respond_temperature = SAMPLE_PASSAGES_RESPOND_TEMP,\n",
    "):\n",
    "    prompt_padded = f\"{prompt}. Answer in {respond_length} sentences and around {respond_word_counter} words\"\n",
    "    sample_passages = []\n",
    "    \n",
    "    for _ in range(sample_passages_size):\n",
    "        sample_passage = LLM.get_respond(prompt=prompt_padded, temperature=respond_temperature)\n",
    "        sample_passages.append(sample_passage)\n",
    "    return sample_passages\n",
    "\n",
    "def get_respond_length(respond: str) -> int:\n",
    "    respond = respond.strip()\n",
    "    return len(re.split(SENTENCE_ENDINGS, respond))\n",
    "\n",
    "def get_respond_word_couner(respond: str) -> int:\n",
    "    return len(re.findall(r'\\b\\w+\\b', respond))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Sample Passages to HaluEval 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sampled_passages():\n",
    "    logging.basicConfig(level=logging.INFO, filename=\"../data/logs/dataset_modifier.log\", filemode='w')\n",
    "    print(\"Start adding sample passages.\")\n",
    "\n",
    "    for category in dataset_halu_eval.keys():\n",
    "        logging.info(f\"Checking category: {category}\")\n",
    "        print(f\"Working w/ category: {category}\")\n",
    "        \n",
    "        # Set up parameters\n",
    "        output_path = os.path.join(OUTPUT_DIR, f\"halu_eval_2/{category}.json\")\n",
    "        dataset = dataset_halu_eval[category]\n",
    "        if category in dataset_halu_eval_processed:\n",
    "            dataset_output = dataset_halu_eval_processed[category]\n",
    "            processed_ids = [d.get('id') for d in dataset_output]\n",
    "        else: \n",
    "            dataset_output = []\n",
    "            processed_ids = []\n",
    "        \n",
    "        for i, sample in enumerate(tqdm(dataset)):\n",
    "            sample = dataset[i]\n",
    "            \n",
    "            # Check if the sample has already been processed\n",
    "            if sample['id'] in processed_ids:\n",
    "                continue\n",
    "            # Process sample\n",
    "            sample['sample_passages'] = get_sample_passages(\n",
    "                sample['user_query'], \n",
    "                get_respond_length(sample['chatgpt_response']),\n",
    "                get_respond_word_couner(sample['chatgpt_response']))\n",
    "            dataset_output.append(sample)\n",
    "            logging.info(f\"Process sample number: {i}, w/ sample id: {sample['id']}\")\n",
    "        with open(output_path, 'w') as fout:\n",
    "            json.dump(dataset_output, fout, indent=2)\n",
    "        print(f\"Finish category: {category}\")\n",
    "    logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start adding sample passages.\n",
      "Working w/ category: Bio-Medical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish category: Bio-Medical\n",
      "Working w/ category: Education\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [51:28<00:00, 15.44s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish category: Education\n",
      "Working w/ category: Finance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:20:23<00:00, 24.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish category: Finance\n",
      "Working w/ category: Open-Domain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [17:59<00:00,  5.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish category: Open-Domain\n",
      "Working w/ category: Science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [2:11:20<00:00, 39.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish category: Science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_sampled_passages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
