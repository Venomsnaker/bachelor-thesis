{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"self_check_gpt\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper.utils import read_data\n",
    "from self_check_gpt import modeling_selfcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load HaluEval 2.0\n",
      "Length of Bio-Medical: 200.\n",
      "Length of Education: 200.\n",
      "Length of Finance: 200.\n",
      "Length of Open-Domain: 200.\n",
      "Length of Science: 200.\n",
      "\n",
      "Loading SelfCheckGPT\n",
      "The length of the dataset: 238.\n"
     ]
    }
   ],
   "source": [
    "FOLDER_PATH_HALUEVAL = \"data/halu_eval_2\"\n",
    "FILE_PATH_SELFCHECKGPT = \"data/self_check_gpt/dataset_v3.json\"\n",
    "\n",
    "dataset_halueval, dataset_selfcheckgpt = read_data(FOLDER_PATH_HALUEVAL, FILE_PATH_SELFCHECKGPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate OpenAI client... model = solar-pro\n",
      "SelfCheck-1gram initialized\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_ENDINGS = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!|\\n)\\s*'\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('UPSTAGE_API_KEY')\n",
    "\n",
    "selfcheckgpt_prompt = modeling_selfcheck.SelfCheckAPIPrompt(\n",
    "    client_type=\"openai\", \n",
    "    base_url=\"https://api.upstage.ai/v1/solar\", \n",
    "    model=\"solar-pro\", \n",
    "    api_key=api_key)\n",
    "selfcheckgpt_unigram = modeling_selfcheck.SelfCheckNgram(\n",
    "    n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "### Benchmark: Halu Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_halueval = \"data\\scores\\halu_eval_2\"\n",
    "\n",
    "for category in dataset_halueval.keys():\n",
    "    output_path_category = Path(os.path.join(output_folder_halueval, category))\n",
    "    \n",
    "    if not output_path_category.is_file():\n",
    "        output_path_category.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:04<00:00,  1.09it/s]\n",
      "100%|██████████| 200/200 [02:38<00:00,  1.26it/s]\n",
      "100%|██████████| 200/200 [03:44<00:00,  1.12s/it]\n",
      "100%|██████████| 200/200 [01:35<00:00,  2.08it/s]\n",
      "100%|██████████| 200/200 [04:58<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "def perform_halueval_unigram():\n",
    "    for category in dataset_halueval.keys():\n",
    "        samples = dataset_halueval[category]\n",
    "        output_path = os.path.join(output_folder_halueval, category, \"scores_selfcheckgpt_1gram.json\")\n",
    "        scores_halueval_unigram = {}\n",
    "        \n",
    "        for i, sample in enumerate(tqdm(samples)):\n",
    "            response = sample['chatgpt_response']\n",
    "            setences = re.split(SENTENCE_ENDINGS, response)\n",
    "            sentences = [s.strip() for s in setences if s.strip()]\n",
    "            \n",
    "            scores_halueval_unigram[sample['id']] = selfcheckgpt_unigram.predict(\n",
    "                passage=response,\n",
    "                sentences=sentences,\n",
    "                sampled_passages=sample['sample_passages'],\n",
    "            )\n",
    "        \n",
    "        with open(output_path, 'w') as outfile:\n",
    "            json.dump(scores_halueval_unigram, outfile)\n",
    "    \n",
    "perform_halueval_unigram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT Prompt API - Solar Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_halueval_prompt():\n",
    "    for category in dataset_halueval.keys():\n",
    "        samples = dataset_halueval[category]\n",
    "        output_path = os.path.join(output_folder_halueval, category, \"scores_selfcheckgpt_prompt_solar_pro.json\")\n",
    "        scores_halueval_prompt = {}\n",
    "        \n",
    "        for i, sample in enumerate(tqdm(samples)):\n",
    "            response = sample['chatgpt_response']\n",
    "            setences = re.split(SENTENCE_ENDINGS, response)\n",
    "            sentences = [s.strip() for s in setences if s.strip()]\n",
    "            \n",
    "            scores = selfcheckgpt_prompt.predict(\n",
    "                sentences=sentences,\n",
    "                sample_passages=sample['sample_passages'],\n",
    "            )\n",
    "            scores_halueval_prompt[sample['id']] = list(scores)\n",
    "        \n",
    "        with open(output_path, 'w') as outfile:\n",
    "            json.dump(scores_halueval_prompt, outfile)\n",
    "            \n",
    "# perform_halueval_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: SelfCheckGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_selfcheckgpt = \"data\\scores\\self_check_gpt\"\n",
    "output_path = Path(output_folder_selfcheckgpt)\n",
    "\n",
    "if not output_path.is_file():\n",
    "    output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_selfcheckgpt_unigram():\n",
    "    scores_selfcheckgpt_unigram = {} \n",
    "    output_path = os.path.join(output_folder_selfcheckgpt, \"scores_selfcheckgpt_1gram.json\")\n",
    "\n",
    "    for i, sample in enumerate(tqdm(dataset_selfcheckgpt)):\n",
    "        scores_selfcheckgpt_unigram[sample['wiki_bio_test_idx']] = selfcheckgpt_unigram.predict(\n",
    "            passage=sample['gpt3_text'],\n",
    "            sentences=sample['gpt3_sentences'],\n",
    "            sampled_passages=sample['gpt3_text_samples'],\n",
    "        )\n",
    "        \n",
    "    with open(output_path, 'w') as outfile:\n",
    "        json.dump(scores_selfcheckgpt_unigram, outfile)\n",
    "        \n",
    "# perform_selfcheckgpt_unigram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT Prompt API - Solar Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_selfcheck_prompt():\n",
    "    scores_selfcheckgpt_prompt = {}\n",
    "    output_path = os.path.join(output_folder_selfcheckgpt, \"scores_selfcheckgpt_prompt_solar_pro.json\")\n",
    "\n",
    "    for i, sample in enumerate(tqdm(dataset_selfcheckgpt)):\n",
    "        scores = selfcheckgpt_prompt.predict(\n",
    "            sentences=sample['gpt3_sentences'],\n",
    "            sample_passages=sample['gpt3_text_samples'],\n",
    "        )\n",
    "        scores_selfcheckgpt_prompt[sample['wiki_bio_test_idx']] = list(scores)\n",
    "\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        json.dump(scores_selfcheckgpt_prompt, outfile)\n",
    "        \n",
    "# perform_selfcheck_prompt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
