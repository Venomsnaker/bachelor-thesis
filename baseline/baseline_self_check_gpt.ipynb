{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"self_check_gpt\")\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from baseline.helper.utils import read_data\n",
    "from self_check_gpt import modeling_selfcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load HaluEval 2.0\n",
      "Length of Bio-Medical: 200.\n",
      "Length of Education: 200.\n",
      "Length of Finance: 200.\n",
      "Length of Open-Domain: 200.\n",
      "Length of Science: 200.\n",
      "\n",
      "Loading SelfCheckGPT\n",
      "The length of the dataset: 238.\n"
     ]
    }
   ],
   "source": [
    "dataset_halu_eval, dataset_self_check_gpt = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate OpenAI client... model = solar-pro\n",
      "SelfCheck-1gram initialized\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('UPSTAGE_API_KEY')\n",
    "self_check_gpt_prompt = modeling_selfcheck.SelfCheckAPIPrompt(\n",
    "    client_type=\"openai\", \n",
    "    base_url=\"https://api.upstage.ai/v1/solar\", \n",
    "    model=\"solar-pro\", \n",
    "    api_key=api_key)\n",
    "self_check_gpt_ngram = modeling_selfcheck.SelfCheckNgram(\n",
    "    n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "### Benchmark: Halu Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.Series(dataset_halu_eval['Bio-Medical'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10,\n",
       " 'user_query': 'Name synonym of Acrokeratosis paraneoplastica.',\n",
       " 'chatgpt_response': 'The possible synonyms for Acrokeratosis paraneoplastica are:\\n- Bazex syndrome\\n- Bazex-Dupré-Christol syndrome\\n- Acrokeratosis neoplastica\\n- Triad syndrome\\n- Bazex syndrome of multiple basal cell carcinomas\\n- Bazex syndrome of carcinomas of pharynx and esophagus\\n- Fingerprint-acral-keratoderma - Specifically for the clinical presentation of palmoplantar keratoderma with dermatoscopic abnormal hand fingerprint patterns.',\n",
       " 'chatgpt_fact': ['Bazex syndrome is a synonym for Acrokeratosis paraneoplastica.',\n",
       "  'Bazex-Dupré-Christol syndrome is another name for Acrokeratosis paraneoplastica.',\n",
       "  'Acrokeratosis neoplastica and Triad syndrome are also synonymous with Acrokeratosis paraneoplastica.',\n",
       "  \"'Bazex syndrome of multiple basal cell carcinomas' and 'Bazex syndrome of carcinomas of pharynx and esophagus' are alternative names for Acrokeratosis paraneoplastica.\",\n",
       "  \"The term 'Fingerprint-acral-keratoderma' is specifically connected to the clinical presentation of palmoplantar keratoderma with dermatoscopic abnormal hand fingerprint patterns as a substitute for Acrokeratosis paraneoplastica.\"],\n",
       " 'human_judge': ['true', 'false', 'false', 'false', 'false']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_selfcheckgpt_unigram_halueval = {}\n",
    "\n",
    "for i in tqdm(range(len(samples))):\n",
    "    sample = samples[i]\n",
    "    idx = sample['id']\n",
    "    prompt = sample['user_query']\n",
    "    response = sample['chatgpt_response']\n",
    "    \n",
    "    setences = re.split(r'\\.|\\n', response)\n",
    "    sentences = [s.strip() for s in setences if s.strip()]\n",
    "    sampled_passages = self_check_gpt_ngram.get_sample_passages(prompt)\n",
    "    \n",
    "    scores_prompt[sample['id']] = selfcheck_prompt.predict(\n",
    "        sentences=sentences,\n",
    "        sampled_passages=sampled_passages,\n",
    "        verbose=True\n",
    "    )\n",
    "scores_prompt = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT Prompt API - Solar Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_selfcheckgpt_prompt_halueval = {}\n",
    "\n",
    "for i in tqdm(range(len(samples))):\n",
    "    sample = samples[i]\n",
    "    prompt = sample['user_query']\n",
    "    response = sample['chatgpt_response']\n",
    "    setences = re.split(r'\\.|\\n', response)\n",
    "    sentences = [s.strip() for s in setences if s.strip()]\n",
    "    sampled_passages = selfcheck_prompt.get_sample_passages(prompt)\n",
    "    \n",
    "    scores_prompt[sample['id']] = selfcheck_prompt.predict(\n",
    "        sentences=sentences,\n",
    "        sampled_passages=sampled_passages,\n",
    "        verbose=True\n",
    "    )\n",
    "scores_prompt = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: SelfCheckGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfCheckGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
