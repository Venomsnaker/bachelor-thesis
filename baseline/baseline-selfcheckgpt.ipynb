{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "\n",
      "Loading HaluEval\n",
      "Length of dialogue_data: 10000\n",
      "Length of general_data: 4507\n",
      "Length of qa_data: 10000\n",
      "Length of summarization_data: 10000\n",
      "\n",
      "Loading HaluEval 2.0\n",
      "Length of Bio-Medical: 200\n",
      "Length of Education: 200\n",
      "Length of Finance: 200\n",
      "Length of Open-Domain: 200\n",
      "Length of Science: 200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "folder_path_halu_eval_2 = 'benchmark/halu_eval_2/annotation/human_annotation'\n",
    "folder_path_halu_eval = 'benchmark/halu_eval/data'\n",
    "\n",
    "def read_data(folder_path_halu_eval, folder_path_halu_eval_2):\n",
    "    \"\"\"\n",
    "        Return a list = [Halu Eval Dataset, Halu Eval 2.0 Dataset]\n",
    "    \"\"\"\n",
    "    print(\"Loading Data\", end=\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Loading HaluEval\")\n",
    "    dataset_halu_eval = {}\n",
    "    \n",
    "    for file_name in os.listdir(folder_path_halu_eval):\n",
    "        file_path = os.path.join(folder_path_halu_eval, file_name)\n",
    "        file_name = file_name.replace(\".json\", \"\")\n",
    "        content = []\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                content.append(json.loads(line))\n",
    "            dataset_halu_eval[file_name] = content\n",
    "        print(f\"Length of {file_name}: {len(dataset_halu_eval[file_name])}\" )\n",
    "\n",
    "    print()\n",
    "    print(\"Loading HaluEval 2.0\")\n",
    "    dataset_halu_eval_2 = {}\n",
    "    \n",
    "    for file_name in os.listdir(folder_path_halu_eval_2):\n",
    "        file_path = os.path.join(folder_path_halu_eval_2, file_name)\n",
    "        file_name = file_name.replace(\".json\", \"\")\n",
    "        \n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "        dataset_halu_eval_2[file_name] = json.loads(content)\n",
    "        print(f\"Length of {file_name}: {len(dataset_halu_eval_2[file_name])}\")\n",
    "        \n",
    "    return [dataset_halu_eval, dataset_halu_eval_2]\n",
    "        \n",
    "dataset_halueval, dataset_halueval2 = read_data(folder_path_halu_eval, folder_path_halu_eval_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up SelfCheckGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate OpenAI client... model = solar-pro\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "sys.path.append(\"self_check_gpt\")\n",
    "from self_check_gpt import modeling_selfcheck\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('UPSTAGE_API_KEY')\n",
    "selfcheck_prompt = modeling_selfcheck.SelfCheckAPIPrompt(client_type=\"openai\", base_url=\"https://api.upstage.ai/v1/solar\", model=\"solar-pro\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10,\n",
       " 'user_query': 'Name synonym of Acrokeratosis paraneoplastica.',\n",
       " 'chatgpt_response': 'The possible synonyms for Acrokeratosis paraneoplastica are:\\n- Bazex syndrome\\n- Bazex-Dupré-Christol syndrome\\n- Acrokeratosis neoplastica\\n- Triad syndrome\\n- Bazex syndrome of multiple basal cell carcinomas\\n- Bazex syndrome of carcinomas of pharynx and esophagus\\n- Fingerprint-acral-keratoderma - Specifically for the clinical presentation of palmoplantar keratoderma with dermatoscopic abnormal hand fingerprint patterns.',\n",
       " 'chatgpt_fact': ['Bazex syndrome is a synonym for Acrokeratosis paraneoplastica.',\n",
       "  'Bazex-Dupré-Christol syndrome is another name for Acrokeratosis paraneoplastica.',\n",
       "  'Acrokeratosis neoplastica and Triad syndrome are also synonymous with Acrokeratosis paraneoplastica.',\n",
       "  \"'Bazex syndrome of multiple basal cell carcinomas' and 'Bazex syndrome of carcinomas of pharynx and esophagus' are alternative names for Acrokeratosis paraneoplastica.\",\n",
       "  \"The term 'Fingerprint-acral-keratoderma' is specifically connected to the clinical presentation of palmoplantar keratoderma with dermatoscopic abnormal hand fingerprint patterns as a substitute for Acrokeratosis paraneoplastica.\"],\n",
       " 'human_judge': ['true', 'false', 'false', 'false', 'false']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_halueval2['Bio-Medical'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:23<00:00,  2.94s/it]\n",
      "100%|██████████| 1/1 [00:31<00:00, 31.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: array([0. , 0. , 1. , 1. , 1. , 0.2, 1. , 1. ])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "samples = pd.Series(dataset_halueval2['Bio-Medical'])[:1]\n",
    "scores_prompt = {}\n",
    "\n",
    "for i in tqdm(range(len(samples))):\n",
    "    sample = samples[i]\n",
    "    prompt = sample['user_query']\n",
    "    response = sample['chatgpt_response']\n",
    "    setences = re.split(r'\\.|\\n', response)\n",
    "    sentences = [s.strip() for s in setences if s.strip()]\n",
    "    sampled_passages = selfcheck_prompt.get_sample_passages(prompt)\n",
    "    \n",
    "    scores_prompt[sample['id']] = selfcheck_prompt.predict(\n",
    "        sentences=sentences,\n",
    "        sampled_passages=sampled_passages,\n",
    "        verbose=True\n",
    "    )\n",
    "scores_prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
