{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ae17e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of HaluEval data: 300\n",
      "\n",
      "Reconstruct prompt: \n",
      "Query: You are given an answer. Your task is to generate the original question that was asked to get this answer. Make sure the original question you create explicitly includes the key information provided in the given answer. Only return the original question.\n",
      "\n",
      "Answer: \"{answer}\"\n",
      "\n",
      "Original Question:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data_halu_eval\n",
    "\n",
    "halu_eval_file_path = '../data/interrogate_llm/halu_eval/halu_eval_sample.json'\n",
    "output_halu_eval_file_path = '../data/output/interrogate_llm_zeroshot/halu_eval_output.json'\n",
    "reconstruct_prompt_file_path = 'prompts/reconstruct.txt'\n",
    "\n",
    "data = load_data_halu_eval(halu_eval_file_path)\n",
    "\n",
    "with open(reconstruct_prompt_file_path, 'r', encoding='utf-8') as f:\n",
    "    reconstruct_prompt_template = f.read()\n",
    "\n",
    "print(f\"Length of HaluEval data: {len(data)}\\n\")\n",
    "print(f\"Reconstruct prompt: \\n{reconstruct_prompt_template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd067b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ebc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gpt_model import OpenAIClient\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAIClient(api_key=openai_api_key,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2be2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|██████████| 300/300 [04:01<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "result = []\n",
    "\n",
    "for idx, sample in enumerate(tqdm(data, desc=\"Processing samples\")):\n",
    "    answer = sample['answer']\n",
    "    reconstruct_prompt = reconstruct_prompt_template.replace('{answer}', answer)\n",
    "    response = client.generate_response(reconstruct_prompt)\n",
    "    result.append(\n",
    "        {\n",
    "            \"id\": sample['id'],\n",
    "            \"knowledge\": sample[\"knowledge\"],\n",
    "            \"ground_truth\": sample[\"ground_truth\"],\n",
    "            \"question\": sample[\"question\"],\n",
    "            \"answer\": sample[\"answer\"],\n",
    "            \"reconstruct_question\": response.strip('\"'),\n",
    "            \"is_hallucinated\": sample['is_hallucinated']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdc8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(output_halu_eval_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
